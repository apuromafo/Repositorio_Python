import re
import sys
import asyncio
from playwright.async_api import async_playwright
import argparse
from urllib.parse import quote
import json

# === CONFIGURACI√ìN ===
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',
}

# === FUNCIONES ===

async def find_details_url(page, linkedin_url):
    """
    Usa Playwright para navegar a la p√°gina de b√∫squeda y encontrar la URL
    completa del reporte de detalles.
    """
    try:
        encoded_url = quote(linkedin_url, safe='')
        double_encoded_url = quote(encoded_url, safe='')
        search_url = f"https://www.virustotal.com/gui/search/{double_encoded_url}"

        print(f"\nüîé Paso 1: Buscando URL de detalles para: {linkedin_url}")
        print(f"üåê Accediendo a la p√°gina de b√∫squeda: {search_url}")

        await page.goto(search_url, wait_until="domcontentloaded", timeout=30000)
        
        print("‚è≥ Esperando la redirecci√≥n o la actualizaci√≥n de la URL...")
        
        await page.wait_for_url(re.compile(r"virustotal\.com/gui/url/[a-f0-9]{64}"), timeout=15000)
        
        current_url = page.url
        
        if "/details" not in current_url:
            details_url = current_url + "/details"
        else:
            details_url = current_url

        print(f"‚úÖ URL de detalles del reporte encontrada: {details_url}")
        
        return details_url

    except Exception as e:
        print(f"‚ùå Error al procesar {linkedin_url}: {e}")
        return None
    finally:
        print("--- Proceso de b√∫squeda de URL completado ---")
        await asyncio.sleep(3)

async def find_all_details_urls(text):
    """
    Procesa cada URL lnkd.in, una por una, para encontrar la URL de detalles.
    """
    linkedin_urls = sorted(list(set(re.findall(r"https://lnkd\.in/[a-zA-Z0-9./_?&=-]+", text))))
    if not linkedin_urls:
        return {}

    details_urls = {}
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(extra_http_headers=HEADERS)
        page = await context.new_page()

        try:
            for url in linkedin_urls:
                details_url = await find_details_url(page, url)
                details_urls[url] = details_url
        finally:
            await browser.close()
    
    return details_urls

# === ENTRADA/SALIDA ===

def read_input_from_cli():
    """Lee la entrada est√°ndar para el texto a procesar."""
    print("--- LinkedIn URL Resolver (Paso 1) ---")
    print("Pega las URLs de LinkedIn que quieres verificar.")
    print("Presiona Ctrl+D (Unix) o Ctrl+Z (Windows) y Enter para finalizar.")
    lines = sys.stdin.readlines()
    return "".join(lines)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Resuelve enlaces acortados de LinkedIn (lnkd.in) y se detiene en la URL de detalles de VirusTotal."
    )
    parser.add_argument(
        "-a", "--archivo",
        help="Ruta al archivo de texto de entrada para procesar."
    )
    parser.add_argument(
        "-o", "--output",
        default="poc.txt",
        help="Ruta al archivo donde se guardar√° el JSON de URLs de detalles. (por defecto: poc.txt)"
    )

    args = parser.parse_args()

    input_text = ""
    if args.archivo:
        try:
            with open(args.archivo, 'r', encoding='utf-8') as f:
                input_text = f.read()
            print(f"Leyendo texto desde: {args.archivo}")
        except FileNotFoundError:
            print(f"Error: El archivo '{args.archivo}' no fue encontrado.", file=sys.stderr)
            sys.exit(1)
        except Exception as e:
            print(f"Error al leer el archivo '{args.archivo}': {e}", file=sys.stderr)
            sys.exit(1)
    else:
        input_text = read_input_from_cli()

    if input_text.strip():
        print("\nüöÄ Iniciando navegador para encontrar URLs de detalles...")
        details_urls = asyncio.run(find_all_details_urls(input_text))
        
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                # Guardamos los resultados como JSON para que sea f√°cil de leer en el siguiente script
                json.dump(details_urls, f, indent=4)
            print(f"\n‚úÖ Resultados guardados en: {args.output}")
        except Exception as e:
            print(f"‚ùå Error al escribir en el archivo '{args.output}': {e}", file=sys.stderr)
            sys.exit(1)
    else:
        print("\nüö´ No se ingres√≥ texto para procesar.")